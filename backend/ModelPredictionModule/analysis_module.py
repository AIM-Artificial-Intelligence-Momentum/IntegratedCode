import os
import joblib
import pandas as pd
import numpy as np
from typing import List
from sklearn.metrics import roc_curve, precision_recall_curve
from sklearn.preprocessing import label_binarize

#from AzureServiceModule.AzureSQLClient import execute_query

FILE_DIR = os.path.dirname(__file__)
MODEL_DIR = os.path.join(FILE_DIR, "models")

def load_model(model_name: str):
    """
    model_name: ì˜ˆ) 'xgb_reg_accumulated_sales_planning' (í™•ì¥ì ì œì™¸)
    models í´ë”ì—ì„œ í•´ë‹¹ pkl íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    model_path = os.path.join(MODEL_DIR, f"{model_name}.pkl")
    model = joblib.load(model_path)
    return model


# --------------------------------
# ë”ë¯¸ê°’ ë°˜í™˜ ëª¨ë“ˆ (ì‹¤ì œ ML ì˜ˆì¸¡ ëŒ€ì‹ )
# --------------------------------

FILE_DIR = os.path.dirname(__file__)
MODEL_DIR = os.path.join(FILE_DIR, "models")

# -----------------
# 1) íšŒê·€ ì˜ˆì¸¡ í•¨ìˆ˜ë“¤ (ë”ë¯¸ê°’)
# -----------------

def predict_acc_sales_planning(input_data: List[dict]) -> dict:
    """
    (ê¸°íš ë‹¨ê³„) ê´€ê° ìˆ˜ ì˜ˆì¸¡ - ê³ ì • ë”ë¯¸ê°’ ë°˜í™˜
    """
    # ì…ë ¥ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ ì˜ˆì¸¡ ëŒ€ì‹  ê³ ì •ê°’ ì‚¬ìš©
    dummy = 8750
    return {
        "predictions": [dummy],
        "comparison": {
            "performances": [
                {"performance_id": 101, "performance_name": "ë®¤ì§€ì»¬ ìº£ì¸ ", "actual": 2800, "predicted": dummy},
                {"performance_id": 102, "performance_name": "ì½˜ì„œíŠ¸ ì•„ì´ìœ ", "actual": 3000, "predicted": dummy + 120},
                {"performance_id": 103, "performance_name": "ì˜¤í˜ë¼ ì¹´ë¥´ë©˜", "actual": 2500, "predicted": dummy - 80},
                {"performance_id": 104, "performance_name": "ì—°ê·¹ ì—°ì• í˜ëª…", "actual": 2900, "predicted": dummy + 50},
                {"performance_id": 105, "performance_name": "ë¬´ìš© ê³µì—° ë¶ˆë¦¿", "actual": 2700, "predicted": dummy - 30}
            ]
        },
        "capacity_scatter": {
            "data": [
                {"performance_id": 101, "capacity": 500, "predicted_sales": dummy, "genre": "ë®¤ì§€ì»¬"},
                {"performance_id": 102, "capacity": 750, "predicted_sales": dummy + 50, "genre": "ë®¤ì§€ì»¬"},
                {"performance_id": 103, "capacity": 600, "predicted_sales": dummy - 30, "genre": "ë®¤ì§€ì»¬"}
            ]
        },
        "time_series": {
            "dates": ["2025-05-01", "2025-05-02", "2025-05-03", "2025-05-04", "2025-05-05"],
            "predicted_cumulative": [1000, 2000, dummy, dummy + 150, dummy + 300],
            "confidence_interval": {
                "lower": [950, 1900, dummy - 20, dummy + 130, dummy + 280],
                "upper": [1050, 2100, dummy + 20, dummy + 170, dummy + 320]
            }
        }
    }


def predict_acc_sales_selling(input_data: List[dict]) -> dict:
    """
    (íŒë§¤ ë‹¨ê³„) ê´€ê° ìˆ˜ ì˜ˆì¸¡ - ê³ ì • ë”ë¯¸ê°’ ë°˜í™˜
    """
    dummy = 20000
    return {
        "predictions": [dummy],
        "time_series": {
            "dates": ["2025-06-01", "2025-06-02", "2025-06-03", "2025-06-04"],
            "actual_cumulative": [1100, 2000, 3000, dummy],
            "predicted_cumulative": [1150, 2050, 3100, dummy]
        },
        "capacity_scatter": {
            "data": [
                {"performance_id": 201, "capacity": 500, "accumulated_sales": dummy},
                {"performance_id": 202, "capacity": 750, "accumulated_sales": dummy - 100},
                {"performance_id": 203, "capacity": 600, "accumulated_sales": dummy + 50}
            ]
        },
        "comparison": {
            "performances": [
                {"performance_id": 201, "performance_name": "ë®¤ì§€ì»¬ ì´í”„ëŒ„", "actual": 1200, "predicted": dummy},
                {"performance_id": 202, "performance_name": "ì½˜ì„œíŠ¸ ì•„ì´ìœ ", "actual": 950, "predicted": dummy - 40},
                {"performance_id": 203, "performance_name": "ì˜¤í˜ë¼ ì¹´ë¥´ë©˜", "actual": 1100, "predicted": dummy + 30}
            ]
        }
    }


def predict_roi_bep_planning(input_data: List[dict]) -> dict:
    """
    (ê¸°íš ë‹¨ê³„) ì†ìµ ì˜ˆì¸¡ - ê³ ì • ë”ë¯¸ê°’ ë°˜í™˜
    """
    roi_dummy = 0.1245
    bep_dummy = 9200
    return {
        "predictions": [[roi_dummy, bep_dummy]],
        "roi_bep_detail": {
            "total_revenue": 35000000,
            "total_cost": 42000000,
            "fixed_cost": 60000000,
            "variable_cost_rate": 0.2
        },
        "roi_time_series": {
            "dates": ["ì‹œë®¬ë ˆì´ì…˜1", "ì‹œë®¬ë ˆì´ì…˜2", "ì‹œë®¬ë ˆì´ì…˜3", "ì‹œë®¬ë ˆì´ì…˜4", "ì‹œë®¬ë ˆì´ì…˜5"],
            "roi_values": [-0.85, -0.84, -0.83, roi_dummy, -0.86]
        },
        "roi_distribution": {
            "roi_values": [-0.85, -0.84, -0.83, roi_dummy, -0.86],
            "bep_values": [3400, 3410, 3420, bep_dummy, 3430]
        }
    }


def predict_roi_bep_selling(input_data: List[dict]) -> dict:
    """
    (íŒë§¤ ë‹¨ê³„) ì†ìµ ì˜ˆì¸¡ - ê³ ì • ë”ë¯¸ê°’ ë°˜í™˜
    """
    roi_dummy = 0.185
    bep_dummy = 9500
    return {
        "predictions": [[roi_dummy, bep_dummy]],
        "comparison": {
            "actual": {"accumulated_sales": 50000, "total_revenue": 40000000, "total_cost": 45000000},
            "predicted": {"accumulated_sales": 50000, "roi": roi_dummy, "bep": bep_dummy}
        },
        "time_series": {
            "dates": ["2025-07-01", "2025-07-02", "2025-07-03"],
            "actual_cumulative": [15000, 35000, 50000],
            "predicted_cumulative": [15500, 36000, 50000],
            "confidence_interval": {"lower": [15000, 34000, 48000], "upper": [16000, 37000, 52000]}
        }
    }


def predict_ticket_risk(input_data: List[dict]) -> dict:
    """
    (íŒë§¤ ë‹¨ê³„) í‹°ì¼“ ìœ„í—˜ ì˜ˆì¸¡ - ê³ ì • ë”ë¯¸ê°’ ë°˜í™˜
    """
    # booking_rate ê¸°ë°˜ ê²½ê³  í…ìŠ¤íŠ¸
    booking_rate = input_data[0].get("booking_rate", 0)
    if booking_rate >= 75:
        warning_text = "ì•ˆì • (ì €ìœ„í—˜)"
    elif booking_rate >= 60:
        warning_text = "ì¤‘ìœ„í—˜"
    else:
        warning_text = "ê³ ìœ„í—˜"

    return {
        "risk_labels": [0],
        "risk_detail": {"current_booking_rate": booking_rate, "target_booking_rate": 75, "warning": warning_text}
    }


# # -----------------
# # 1) íšŒê·€ ì˜ˆì¸¡ í•¨ìˆ˜ë“¤
# # -----------------

# def predict_acc_sales_planning(input_data: List[dict]) -> dict:
#     """
#     (ê¸°íš ë‹¨ê³„) ê´€ê° ìˆ˜ ì˜ˆì¸¡
#     ëª¨ë¸ íŒŒì¼: xgb_reg_accumulated_sales_planning.pkl
#     """
#     model = load_model("xgb_reg_accumulated_sales_planning")
#     df = pd.DataFrame(input_data)
#     preds = model.predict(df)
    
#     comparison_data = [
#         {"performance_id": 101, "performance_name": "ë®¤ì§€ì»¬ ìº£ì¸ ", "actual": 2800, "predicted": float(preds[0])},
#         {"performance_id": 102, "performance_name": "ì½˜ì„œíŠ¸ ì•„ì´ìœ ", "actual": 3000, "predicted": float(preds[0]) + 120},
#         {"performance_id": 103, "performance_name": "ì˜¤í˜ë¼ ì¹´ë¥´ë©˜", "actual": 2500, "predicted": float(preds[0]) - 80},
#         {"performance_id": 104, "performance_name": "ì—°ê·¹ ì—°ì• í˜ëª…", "actual": 2900, "predicted": float(preds[0]) + 50},
#         {"performance_id": 105, "performance_name": "ë¬´ìš© ê³µì—° ë¶ˆë¦¿", "actual": 2700, "predicted": float(preds[0]) - 30}
#     ]
    
#     time_series_data = {
#         "dates": ["2025-05-01", "2025-05-02", "2025-05-03", "2025-05-04", "2025-05-05"],
#         "predicted_cumulative": [1000, 2000, float(preds[0]), float(preds[0]) + 150, float(preds[0]) + 300],
#         "confidence_interval": {
#             "lower": [950, 1900, float(preds[0]) - 20, float(preds[0]) + 130, float(preds[0]) + 280],
#             "upper": [1050, 2100, float(preds[0]) + 20, float(preds[0]) + 170, float(preds[0]) + 320]
#         }
#     }
    
#     capacity_scatter = {
#         "data": [
#             {"performance_id": 101, "capacity": 500, "predicted_sales": float(preds[0]), "genre": "ë®¤ì§€ì»¬"},
#             {"performance_id": 102, "capacity": 750, "predicted_sales": float(preds[0]) + 50, "genre": "ë®¤ì§€ì»¬"},
#             {"performance_id": 103, "capacity": 600, "predicted_sales": float(preds[0]) - 30, "genre": "ë®¤ì§€ì»¬"}
#         ]
#     }
    
#     return {
#         "predictions": preds.tolist(),
#         "comparison": {"performances": comparison_data},
#         "capacity_scatter": capacity_scatter,
#         "time_series": time_series_data
#     }


# def predict_acc_sales_selling(input_data: List[dict]) -> dict:
#     """
#     (íŒë§¤ ë‹¨ê³„) ê´€ê° ìˆ˜ ì˜ˆì¸¡
#     ëª¨ë¸ íŒŒì¼: xgb_reg_accumulated_sales_selling.pkl
#     """
#     model = load_model("xgb_reg_accumulated_sales_selling")
#     df = pd.DataFrame(input_data)
#     preds = model.predict(df)
    
#     time_series_data = {
#         "dates": ["2025-06-01", "2025-06-02", "2025-06-03", "2025-06-04"],
#         "actual_cumulative": [1100, 2000, 3000, float(preds[0])],
#         "predicted_cumulative": [1150, 2050, 3100, float(preds[0])]
#     }
    
#     capacity_scatter = {
#         "data": [
#             {"performance_id": 201, "capacity": 500, "accumulated_sales": float(preds[0])},
#             {"performance_id": 202, "capacity": 750, "accumulated_sales": float(preds[0]) - 100},
#             {"performance_id": 203, "capacity": 600, "accumulated_sales": float(preds[0]) + 50}
#         ]
#     }
    
#     comparison_data = [
#         {"performance_id": 201, "performance_name": "ë®¤ì§€ì»¬ ì´í”„ëŒ„", "actual": 1200, "predicted": float(preds[0])},
#         {"performance_id": 202, "performance_name": "ì½˜ì„œíŠ¸ ì•„ì´ìœ ", "actual": 950, "predicted": float(preds[0]) - 40},
#         {"performance_id": 203, "performance_name": "ì˜¤í˜ë¼ ì¹´ë¥´ë©˜", "actual": 1100, "predicted": float(preds[0]) + 30}
#     ]
    
#     return {
#         "predictions": preds.tolist(),
#         "time_series": time_series_data,
#         "capacity_scatter": capacity_scatter,
#         "comparison": {"performances": comparison_data}
#     }


# def predict_roi_bep_planning(input_data: List[dict]) -> dict:
#     """
#     (ê¸°íš ë‹¨ê³„) ì†ìµ ì˜ˆì¸¡
#     ëª¨ë¸ íŒŒì¼: xgb_reg_roi_bep_planning.pkl
#     """
#     model = load_model("xgb_reg_roi_bep_planning")
#     df = pd.DataFrame(input_data)
#     preds = model.predict(df)
    
#     roi_bep_detail = {
#         "total_revenue": 35000000,
#         "total_cost": 42000000,
#         "fixed_cost": 60000000,
#         "variable_cost_rate": 0.2
#     }
    
#     roi_time_series = {
#         "dates": ["ì‹œë®¬ë ˆì´ì…˜1", "ì‹œë®¬ë ˆì´ì…˜2", "ì‹œë®¬ë ˆì´ì…˜3", "ì‹œë®¬ë ˆì´ì…˜4", "ì‹œë®¬ë ˆì´ì…˜5"],
#         "roi_values": [-0.85, -0.84, -0.83, float(preds[0][0]), -0.86]
#     }
    
#     roi_distribution = {
#         "roi_values": [-0.85, -0.84, -0.83, float(preds[0][0]), -0.86],
#         "bep_values": [3400, 3410, 3420, float(preds[0][1]), 3430]
#     }
    
#     return {
#         "predictions": preds.tolist(),
#         "roi_bep_detail": roi_bep_detail,
#         "roi_time_series": roi_time_series,
#         "roi_distribution": roi_distribution
#     }


# def predict_roi_bep_selling(input_data: List[dict]) -> dict:
#     """
#     (íŒë§¤ ë‹¨ê³„) ì†ìµ ì˜ˆì¸¡
#     ëª¨ë¸ íŒŒì¼: xgb_reg_roi_bep_selling.pkl
#     """
#     model = load_model("xgb_reg_roi_bep_selling")
#     df = pd.DataFrame(input_data)
#     preds = model.predict(df)
    
#     comparison_data = {
#         "actual": {
#             "accumulated_sales": 50000,
#             "total_revenue": 40000000,
#             "total_cost": 45000000
#         },
#         "predicted": {
#             "accumulated_sales": 50000,
#             "roi": float(preds[0][0]),
#             "bep": float(preds[0][1])
#         }
#     }
    
#     time_series_data = {
#         "dates": ["2025-07-01", "2025-07-02", "2025-07-03"],
#         "actual_cumulative": [15000, 35000, 50000],
#         "predicted_cumulative": [15500, 36000, 50000],
#         "confidence_interval": {
#             "lower": [15000, 34000, 48000],
#             "upper": [16000, 37000, 52000]
#         }
#     }
    
#     return {
#         "predictions": preds.tolist(),
#         "comparison": comparison_data,
#         "time_series": time_series_data
#     }


# ë¶„ë¥˜: í‹°ì¼“ íŒë§¤ ìœ„í—˜ ì˜ˆì¸¡ (ì¡°ê¸° ê²½ë³´)

# def compute_roc_pr(y_true, y_proba, num_classes=3):
#     """
#     ROC/PR ì»¤ë¸Œ ê³„ì‚°
#     """
#     y_true_bin = label_binarize(y_true, classes=list(range(num_classes)))
#     roc_data = []
#     pr_data = []
#     for i in range(num_classes):
#         fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_proba[:, i])
#         precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_proba[:, i])
#         roc_data.append({
#             "class": i,
#             "fpr": fpr.tolist(),
#             "tpr": tpr.tolist()
#         })
#         pr_data.append({
#             "class": i,
#             "precision": precision.tolist(),
#             "recall": recall.tolist()
#         })
#     return {"roc_curve": roc_data, "pr_curve": pr_data}


def predict_ticket_risk(input_data: List[dict]) -> dict:
    """
    (íŒë§¤ ë‹¨ê³„) í‹°ì¼“ ìœ„í—˜ ì˜ˆì¸¡ ë¶„ë¥˜
    ëª¨ë¸ íŒŒì¼: rf_cls_ticket_risk.pkl
    """
    model = load_model("rf_cls_ticket_risk")
    df = pd.DataFrame(input_data)
    preds = model.predict(df)
    
    try:
        pred_proba = model.predict_proba(df)
    except:
        pred_proba = np.full((df.shape[0], 3), 1/3)

    # (ì´ì§„ë¶„ë¥˜ ëŒ€ì‘, ë“±ë“±) -> ìŠ¤í‚µ...

    # dummy ground truth
    # y_true = np.array([0,1,2])  # ì„ì‹œ
    # evaluation_curves = compute_roc_pr(y_true, pred_proba, num_classes=3)
    
    booking_rate = input_data[0].get("booking_rate", 0)
    if booking_rate >= 75:
        warning_text = "ì•ˆì • (ì €ìœ„í—˜)"
    elif booking_rate >= 60:
        warning_text = "ì¤‘ìœ„í—˜"
    else:
        warning_text = "ê³ ìœ„í—˜"
    
    return {
        "risk_labels": preds.tolist(),
        "risk_detail": {
            "current_booking_rate": booking_rate,
            "target_booking_rate": 75,
            "warning": warning_text
        }}
    #     "evaluation_curves": evaluation_curves
    # }


# -----------------------------------------
# DB ë²„ì „: ì§‘ê³„ ì‹œê°í™” ë°ì´í„° (ì‹¤ì œ í˜¸ì¶œìš©)
# -----------------------------------------

def get_genre_stats_db() -> dict:
    """
    DBì—ì„œ ê°€ì ¸ì˜¤ëŠ” ì¥ë¥´ë³„ í†µê³„
    """
    query = "SELECT * FROM dbo.genre_stats_tb;"
    df = execute_query(query)
    df.rename(columns={
        "ì¥ë¥´": "genre",
        "ê°œë§‰í¸ìˆ˜": "performance_count",
        "ê´€ê°ìˆ˜": "audience",
        "ë§¤ì¶œì•¡": "ticket_revenue"
    }, inplace=True)
    use_cols = ["genre", "performance_count", "audience", "ticket_revenue"]
    df = df[use_cols].fillna(0)
    # groupby or skip if already aggregated
    grouped = df.groupby("genre", as_index=False).sum()
    grouped.sort_values(by="genre", inplace=True)
    
    return {
        "genre_stats": {
            "genre": grouped["genre"].tolist(),
            "performance_count": grouped["performance_count"].astype(int).tolist(),
            "audience": grouped["audience"].astype(int).tolist(),
            "ticket_revenue": grouped["ticket_revenue"].astype(int).tolist()
        }
    }


def get_regional_stats_db() -> dict:
    """
    DBì—ì„œ ê°€ì ¸ì˜¤ëŠ” ì§€ì—­ë³„ í†µê³„
    """
    query = "SELECT * FROM dbo.region_stats_tb;"
    df = execute_query(query)
    df.rename(columns={
        "ì§€ì—­ëª…": "region",
        "ê³µì—°ê±´ìˆ˜": "performance_count",
        "ìƒì—°íšŸìˆ˜": "show_count",
        "ì´í‹°ì¼“íŒë§¤ìˆ˜": "total_ticket_sales",
        "ì´í‹°ì¼“íŒë§¤ì•¡": "total_ticket_revenue"
    }, inplace=True)
    use_cols = ["region", "performance_count", "show_count", "total_ticket_sales", "total_ticket_revenue"]
    df = df[use_cols].fillna(0)
    grouped = df.groupby("region", as_index=False).sum()
    grouped.sort_values(by="region", inplace=True)
    
    return {
        "regional_stats": {
            "region": grouped["region"].tolist(),
            "performance_count": grouped["performance_count"].astype(int).tolist(),
            "show_count": grouped["show_count"].astype(int).tolist(),
            "total_ticket_sales": grouped["total_ticket_sales"].astype(int).tolist(),
            "total_ticket_revenue": grouped["total_ticket_revenue"].astype(int).tolist()
        }
    }


def get_venue_scale_stats_db() -> dict:
    """
    DBì—ì„œ ê°€ì ¸ì˜¤ëŠ” ê³µì—°ì¥ ê·œëª¨ë³„ í†µê³„ (2023/2024)
    """
    query = "SELECT * FROM dbo.facility_stats_tb;"
    df = execute_query(query)
    df.rename(columns={
        "ì—°ë„": "year",
        "ê·œëª¨": "scale",
        "ê³µì—°ê±´ìˆ˜": "performance_count",
        "ì´í‹°ì¼“íŒë§¤ìˆ˜": "total_ticket_sales"
    }, inplace=True)
    use_cols = ["year", "scale", "performance_count", "total_ticket_sales"]
    df = df[use_cols].fillna(0)
    grouped = df.groupby(["year", "scale"], as_index=False).sum()
    grouped.sort_values(by=["year", "scale"], inplace=True)
    
    # ë”ë¯¸ ì˜ˆì‹œì²˜ëŸ¼ 2023 + 2024 ì´ì–´ë¶™ì´ê¸°
    df_2023 = grouped[grouped["year"] == 2023].sort_values(by="scale")
    df_2024 = grouped[grouped["year"] == 2024].sort_values(by="scale")
    year_list = df_2023["year"].astype(int).tolist() + df_2024["year"].astype(int).tolist()
    scale_list = df_2023["scale"].tolist() + df_2024["scale"].tolist()
    perf_list = df_2023["performance_count"].astype(int).tolist() + df_2024["performance_count"].astype(int).tolist()
    sales_list = df_2023["total_ticket_sales"].astype(int).tolist() + df_2024["total_ticket_sales"].astype(int).tolist()
    
    return {
        "venue_scale_stats": {
            "year": year_list,
            "scale": scale_list,
            "performance_count": perf_list,
            "total_ticket_sales": sales_list
        }
    }


# ------------------------------------
# ë”ë¯¸ ë²„ì „: ODBC ë“œë¼ì´ë²„ ì—†ì´ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆëŠ” ì§‘ê³„ ë°ì´í„° (ì‹¤ì œ ì§‘ê³„ì™€ ë™ì¼ ê²°ê³¼ë¡œ ì„¤ì •)
# ------------------------------------
def get_genre_stats() -> dict:
    """
    ì¥ë¥´ë³„ í†µê³„ - ë”ë¯¸ ë²„ì „ì„ 'ì‹¤ì œ DB ê²°ê³¼'ì™€ ë™ì¼í•˜ê²Œ ê°±ì‹ .
    """
    return {
        "genre_stats": {
            "genre": [
                "ëŒ€ì¤‘ë¬´ìš©",
                "ëŒ€ì¤‘ìŒì•…",
                "ë¬´ìš©(ì„œì–‘/í•œêµ­ë¬´ìš©)",
                "ë®¤ì§€ì»¬",
                "ë³µí•©",
                "ì„œì–‘ìŒì•…(í´ë˜ì‹)",
                "ì„œì»¤ìŠ¤/ë§ˆìˆ ",
                "ì—°ê·¹",
                "í•œêµ­ìŒì•…(êµ­ì•…)"
            ],
            "performance_count": [
                115,
                7586,
                1652,
                5963,
                862,
                15845,
                1359,
                5399,
                2556
            ],
            "audience": [
                74897,
                11528584,
                1196316,
                15868658,
                459707,
                6379810,
                1375820,
                5469736,
                865332
            ],
            "ticket_revenue": [
                5232114900,
                1337257477586,
                39483012874,
                923351724391,
                6150390882,
                201011077618,
                68307452991,
                135460853742,
                9751860962
            ]
        }
    }


def get_regional_stats() -> dict:
    """
    ì§€ì—­ë³„ í†µê³„ - ë”ë¯¸ ë²„ì „ì„ 'ì‹¤ì œ DB ê²°ê³¼'ì™€ ë™ì¼í•˜ê²Œ ê°±ì‹ .
    """
    return {
        "regional_stats": {
            "region": [
                "ê°•ì›ë„","ê²½ê¸°","ê²½ê¸°/ì¸ì²œ","ê²½ë‚¨","ê²½ë¶","ê²½ìƒë„","ê´‘ì£¼","ëŒ€êµ¬","ëŒ€ì „","ë¶€ì‚°",
                "ì„œìš¸","ì„¸ì¢…","ìš¸ì‚°","ì¸ì²œ","ì „ë‚¨","ì „ë¼ë„","ì „ë¶","ì œì£¼ë„","ì¶©ë‚¨","ì¶©ë¶","ì¶©ì²­ë„","í•©ê³„"
            ],
            "performance_count": [
                1061,6200,7682,1564,1241,9023,1137,2699,1551,2825,
                23196,363,694,1482,724,2908,1047,574,1026,613,3553,47997
            ],
            "show_count": [
                2023,20085,24338,4517,2446,30292,4157,10212,5876,10499,
                156078,648,2618,4253,3051,10217,3009,3699,2135,2386,11045,237692
            ],
            "total_ticket_sales": [
                582917,4561151,5977633,877624,758169,6397471,807256,2067285,826402,2234348,
                26284380,196873,460045,1416482,400945,1781171,572970,279199,567710,325104,1916089,43218860
            ],
            "total_ticket_revenue": [
                27478563671,209759994957,323572313608,38098318991,23892649690,370460857349,46550414450,117366940722,51950324061,172433773289,
                1812089619145,6973849560,18669174657,113812318651,13269617790,88445301773,28625269533,9396123030,17660121674,17978892075,94563187370,2726005965946
            ]
        }
    }


def get_venue_scale_stats() -> dict:
    """
    ê³µì—°ì¥ ê·œëª¨ë³„ í†µê³„ - ë”ë¯¸ ë²„ì „ì„ 'ì‹¤ì œ DB ê²°ê³¼'ì™€ ë™ì¼í•˜ê²Œ ê°±ì‹ .
    """
    return {
        "venue_scale_stats": {
            "year": [
                2023,2023,2023,2023,2023,2023,2023,
                2024,2024,2024,2024,2024,2024,2024
            ],
            "scale": [
                "1,000~5,000ì„ ë¯¸ë§Œ","10,000ì„ ì´ìƒ","1~300ì„ ë¯¸ë§Œ","300~500ì„ ë¯¸ë§Œ","5,000~10,000ì„ ë¯¸ë§Œ","500~1,000ì„ ë¯¸ë§Œ","ì¢Œì„ ë¯¸ìƒ",
                "1,000~5,000ì„ ë¯¸ë§Œ","10,000ì„ ì´ìƒ","1~300ì„ ë¯¸ë§Œ","300~500ì„ ë¯¸ë§Œ","5,000~10,000ì„ ë¯¸ë§Œ","500~1,000ì„ ë¯¸ë§Œ","ì¢Œì„ ë¯¸ìƒ"
            ],
            "performance_count": [
                4388,196,11253,5207,180,5331,2726,
                3735,86,6616,3742,47,3910,580
            ],
            "total_ticket_sales": [
                9238945,3706546,3908329,3135249,882933,3913562,1251977,
                7293316,1280626,2845973,2353712,291825,2906755,209112
            ]
        }
    }


# # ------------------------------------
# # (êµ¬) ë”ë¯¸ ë²„ì „: ì„ì‹œë¡œ ì‚¬ìš©í•˜ë˜ ì§‘ê³„ ë°ì´í„°
# # ------------------------------------


# def get_genre_stats() -> dict:
#     """
#     ë”ë¯¸ ë²„ì „ (ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ìœ ì§€)
#     """
#     return {
#         "genre_stats": {
#             "genre": ["ë®¤ì§€ì»¬", "ì—°ê·¹", "ì„œì–‘ìŒì•…(í´ë˜ì‹)", "ëŒ€ì¤‘ìŒì•…", "ë¬´ìš©(ì„œì–‘/í•œêµ­)", "í•œêµ­ìŒì•…(êµ­ì•…)", "ì„œì»¤ìŠ¤/ë§ˆìˆ ", "ë³µí•©"],
#             "performance_count": [3006, 2932, 8199, 3970, 840, 1356, 835, 440],
#             "audience": [7831448, 2836558, 3290415, 6302709, 606737, 436947, 692155, 225613],
#             "ticket_revenue": [465122497, 73411508, 100996136, 756977444, 20633422, 4869454, 28565775, 2799943]
#         }
#     }

# def get_regional_stats() -> dict:
#     """
#     ë”ë¯¸ ë²„ì „ (ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ìœ ì§€)
#     """
#     return {
#         "regional_stats": {
#             "region": ["ì„œìš¸", "ê²½ê¸°", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ"],
#             "performance_count": [9966, 2917, 1311, 1279, 687],
#             "show_count": [82160, 10807, 5429, 5146, 2231],
#             "total_ticket_sales": [13384094, 2549324, 1062750, 1002533, 823153],
#             "total_ticket_revenue": [946566611, 127171128, 82282070, 56503689, 76098489]
#         }
#     }

# def get_venue_scale_stats() -> dict:
#     """
#     ë”ë¯¸ ë²„ì „ (ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ìœ ì§€)
#     """
#     year_2023 = [2023] * 7
#     scales = ["0ì„(ì¢Œì„ë¯¸ìƒ)", "1~300ì„ ë¯¸ë§Œ", "300~500ì„ ë¯¸ë§Œ", "500~1,000ì„ ë¯¸ë§Œ",
#               "1,000~5,000ì„ ë¯¸ë§Œ", "5,000~10,000ì„ ë¯¸ë§Œ", "10,000ì„ ì´ìƒ"]
#     perf_count_2023 = [1038, 6840, 4195, 4312, 3792, 112, 115]
#     ticket_sales_2023 = [562122, 3395810, 2720965, 3296964, 8277630, 666529, 2048869]
    
#     year_2024 = [2024] * 7
#     perf_count_2024 = [1493, 7147, 4135, 4558, 4038, 131, 132]
#     ticket_sales_2024 = [898841, 3429763, 2762187, 3504875, 8227156, 734900, 2682816]
    
#     return {
#         "venue_scale_stats": {
#             "year": year_2023 + year_2024,
#             "scale": scales + scales,
#             "performance_count": perf_count_2023 + perf_count_2024,
#             "total_ticket_sales": ticket_sales_2023 + ticket_sales_2024
#         }
#     }


if __name__ == "__main__":
    # ê°„ë‹¨ í…ŒìŠ¤íŠ¸
    import pprint
    
    print("=== DB ë²„ì „: ì¥ë¥´ë³„ ===")
    pprint.pprint(get_genre_stats_db())
    print("\n=== DB ë²„ì „: ì§€ì—­ë³„ ===")
    pprint.pprint(get_regional_stats_db())
    print("\n=== DB ë²„ì „: ê·œëª¨ë³„ ===")
    pprint.pprint(get_venue_scale_stats_db())
    
    print("\n=== ë”ë¯¸ ë²„ì „: ì¥ë¥´ë³„ ===")
    pprint.pprint(get_genre_stats())
    print("\n=== ë”ë¯¸ ë²„ì „: ì§€ì—­ë³„ ===")
    pprint.pprint(get_regional_stats())
    print("\n=== ë”ë¯¸ ë²„ì „: ê·œëª¨ë³„ ===")
    pprint.pprint(get_venue_scale_stats())

ê·¸ë¦¬ê³  ì•„ë˜ ì½”ë“œì—ì„œë„ í•´ë‹¹ ë©”ì‹œì§€ë¥¼ í•¨ê»˜ ë°˜í™˜ì‹œí‚¤ë„ë¡ ì¶”ê°€í•´ ì¤˜

# backend/AzureServiceModule/ChatbotService.py

from .modules.AzureOpenAIClient import get_azure_openai_client
from .modules.IntentClassifier import IntentClassifier
from .modules.StageDetector import StageDetector
from .modules.VariableExtractor import AITextExtractor
from .modules.PromptGenerator import PromptGenerator
from .modules.AISearchClient import AISearchService
from .config.VariableConfig import required_keys, categorical_keys, planning_stage_keys, sales_stage_keys
import json
import re
import httpx  # ë¹„ë™ê¸° HTTP ìš”ì²­ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from datetime import datetime

import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("chatbot")

class ChatbotService:
    def __init__(self, api_key, endpoint, deployment, search_key, search_endpoint, search_index):
        # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = get_azure_openai_client(api_key, endpoint)
        self.deployment = deployment
        
        # 4ê°€ì§€ í•µì‹¬ ê¸°ëŠ¥ ì´ˆê¸°í™”
        self.extractor = AITextExtractor(self.client, self.deployment, required_keys, categorical_keys)  # JSON ë³€ìˆ˜ ì¶”ì¶œê¸°
        self.prompter = PromptGenerator(self.client, self.deployment, categorical_keys)                  # ì±—ë´‡ ì§ˆë¬¸ ìƒì„±ê¸°
        self.search = AISearchService(self.client, self.deployment, search_key, search_endpoint, search_index)  # ë¬¸ì„œ ê²€ìƒ‰ê¸°
        self.detector = StageDetector(self.client, self.deployment)
        self.classifier = IntentClassifier(self.client, self.deployment)

        # ìƒíƒœ ì •ë³´
        self.collected_vars = {}
        self.summary = None
        self.last_asked_key = None
        
        # ML API ê¸°ë³¸ URL (ê°™ì€ ì„œë²„ì—ì„œ ì‹¤í–‰ ì¤‘ì´ë¼ê³  ê°€ì •)
        self.ml_api_base_url = "http://localhost:8000/api/ml"  # í•„ìš”ì— ë”°ë¼ ì¡°ì •
        
    # ë‚ ì§œë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (ML ëª¨ë¸ ì…ë ¥ìš©)
    def _convert_date_to_numeric(self, date_str):
        """YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œë¥¼ 1~365 ì‚¬ì´ì˜ ìˆ«ìë¡œ ë³€í™˜"""
        if not date_str:
            return 1.0  # ê¸°ë³¸ê°’
        
        try:
            date_obj = datetime.strptime(date_str, "%Y-%m-%d")
            day_of_year = date_obj.timetuple().tm_yday  # 1ë¶€í„° 365(366)ê¹Œì§€ì˜ ë‚ ì§œ
            return float(day_of_year)
        except:
            return 1.0  # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’

    # í•„ìš”í•œ ë¶„ì„ ìœ í˜• ê²°ì • í•¨ìˆ˜
    def _determine_analysis_type(self, user_input, stage):
        """ì‚¬ìš©ì ì…ë ¥ê³¼ ë‹¨ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•„ìš”í•œ ë¶„ì„ ìœ í˜• ê²°ì •"""
        # í†µê³„ ë¶„ì„ ìš°ì„  ê²€ì¶œ (ë‹¨ê³„ êµ¬ë¶„ ì—†ìŒ)
        if re.search(r"(ì¥ë¥´ë³„|ì¥ë¥´.{0,5}í†µê³„|ì¥ë¥´.{0,5}ë¶„ì„|ì¥ë¥´.{0,5}ê²°ì‚°|ì¥ë¥´.{0,5}ì¶”ì´)", user_input, re.IGNORECASE):
            return ["genre_stats"]
            
        if re.search(r"(ì§€ì—­ë³„|ì§€ì—­.{0,5}í†µê³„|ì§€ì—­.{0,5}ë¶„ì„|ì§€ì—­.{0,5}ê²°ì‚°|ì§€ì—­.{0,5}ì¶”ì´)", user_input, re.IGNORECASE):
            return ["regional_stats"]
        
        if re.search(r"(ê³µì—°ì¥.{0,5}ê·œëª¨|ê·œëª¨ë³„|ì¢Œì„.{0,5}ê·œëª¨|ê·œëª¨.{0,5}ë¶„ì„)", user_input, re.IGNORECASE):
            return ["venue_scale_stats"]
        
        # í‹°ì¼“ ìœ„í—˜ë„ ë¶„ì„ì€ ë‹¨ê³„ì™€ ê´€ê³„ì—†ì´ ìš”ì²­ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
        if re.search(r"(í‹°ì¼“.{0,5}ìœ„í—˜|ìœ„í—˜.{0,5}ë¶„ì„|í‹°ì¼“.{0,5}ë¦¬ìŠ¤í¬|ìœ„í—˜ë„|ìœ„í—˜|ë¦¬ìŠ¤í¬|ê°€ëŠ¥ì„±|ì‹¤íŒ¨)", user_input, re.IGNORECASE):
            return ["ticket_risk_selling"]
        
        # ê¸°ì¡´ ë¶„ì„ ìœ í˜• (ë‹¨ê³„ êµ¬ë¶„ ì ìš©)
        # ê¸°ë³¸ ë¶„ì„ ìœ í˜•
        if stage == "ê¸°íš":
            analysis_types = ["accumulated_sales_planning", "roi_bep_planning"]
        else:  # íŒë§¤ ë‹¨ê³„
            analysis_types = ["accumulated_sales_selling", "roi_bep_selling", "ticket_risk_selling"]
        
        # íŠ¹ì • ë¶„ì„ ìœ í˜• ê²€ì¶œ
        if re.search(r"(ê´€ê°|í‹°ì¼“|íŒë§¤ëŸ‰|ë§¤ì¶œì•¡)", user_input, re.IGNORECASE):
            if stage == "ê¸°íš":
                return ["accumulated_sales_planning"]
            else:
                return ["accumulated_sales_selling"]
                
        elif re.search(r"(ì†ìµ|ìˆ˜ìµ|ROI|BEP|ì†ìµë¶„ê¸°ì )", user_input, re.IGNORECASE):
            if stage == "ê¸°íš":
                return ["roi_bep_planning"]
            else:
                return ["roi_bep_selling"]
                
        # ëª…í™•í•œ íŒ¨í„´ì´ ì—†ìœ¼ë©´ ë‹¨ê³„ë³„ ê¸°ë³¸ ë¶„ì„ ì‹¤í–‰
        return analysis_types
    
    # ë³€ìˆ˜ í¬ë§· ë³€í™˜ í•¨ìˆ˜
    def _format_variables_for_ml_api(self, analysis_type):
        """ìˆ˜ì§‘ëœ ë³€ìˆ˜ë¥¼ ML API í˜•ì‹ì— ë§ê²Œ ë³€í™˜"""
        formatted_vars = self.collected_vars.copy()
        
        # ë‚ ì§œë¥¼ ìˆ«ìë¡œ ë³€í™˜
        if "start_date" in formatted_vars:
            formatted_vars["start_date_numeric"] = self._convert_date_to_numeric(formatted_vars["start_date"])
        
        # ëª¨ë“  ìˆ«ì í•„ë“œë¥¼ floatë¡œ ë³€í™˜
        numeric_fields = [
            "capacity", "star_power", "ticket_price", "marketing_budget", 
            "sns_mention_count", "daily_sales", "booking_rate", "ad_exposure", 
            "sns_mention_daily", "production_cost", "variable_cost_rate", 
            "accumulated_sales", "duration"
        ]
        
        for field in numeric_fields:
            if field in formatted_vars:
                try:
                    if isinstance(formatted_vars[field], str):
                        # ë¬¸ìì—´ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ
                        formatted_vars[field] = float(''.join(c for c in formatted_vars[field] if c.isdigit() or c == '.'))
                    else:
                        formatted_vars[field] = float(formatted_vars[field])
                except (ValueError, TypeError):
                    # ë³€í™˜ ì‹¤íŒ¨ ì‹œ í•´ë‹¹ í•„ë“œ ì œê±°
                    formatted_vars.pop(field, None)
        
        # promo_event_flagë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
        if "promo_event_flag" in formatted_vars:
            if isinstance(formatted_vars["promo_event_flag"], str):
                formatted_vars["promo_event_flag"] = 1 if formatted_vars["promo_event_flag"].lower() == "true" else 0
            elif isinstance(formatted_vars["promo_event_flag"], bool):
                formatted_vars["promo_event_flag"] = 1 if formatted_vars["promo_event_flag"] else 0
        
        # ë¶„ì„ ìœ í˜•ë³„ í•„ìˆ˜ í•„ë“œ ì„¤ì •
        if analysis_type == "accumulated_sales_planning":
            defaults = {
                "genre": formatted_vars.get("genre", "ë®¤ì§€ì»¬"),
                "region": formatted_vars.get("region", "ì„œìš¸íŠ¹ë³„ì‹œ"),
                "start_date_numeric": formatted_vars.get("start_date_numeric", 1.0),
                "capacity": formatted_vars.get("capacity", 502000.5),
                "star_power": formatted_vars.get("star_power", 280.0),
                "ticket_price": formatted_vars.get("ticket_price", 40439.5),
                "marketing_budget": formatted_vars.get("marketing_budget", 8098512.5),
                "sns_mention_count": formatted_vars.get("sns_mention_count", 38.0),
                "duration": formatted_vars.get("duration", 1)
            }
            return defaults
        
        elif analysis_type == "accumulated_sales_selling":
            defaults = {
                "genre": formatted_vars.get("genre", "ë®¤ì§€ì»¬"),
                "region": formatted_vars.get("region", "ì„œìš¸íŠ¹ë³„ì‹œ"),
                "start_date_numeric": formatted_vars.get("start_date_numeric", 1.0),
                "capacity": formatted_vars.get("capacity", 502000.5),
                "star_power": formatted_vars.get("star_power", 280.0),
                "ticket_price": formatted_vars.get("ticket_price", 40439.5),
                "marketing_budget": formatted_vars.get("marketing_budget", 8098512.5),
                "sns_mention_count": formatted_vars.get("sns_mention_count", 38.0),
                "daily_sales": formatted_vars.get("daily_sales", 2.0),
                "booking_rate": formatted_vars.get("booking_rate", 0.7),
                "ad_exposure": formatted_vars.get("ad_exposure", 303284.5),
                "sns_mention_daily": formatted_vars.get("sns_mention_daily", 38.0),
                "duration": formatted_vars.get("duration", 1)
            }
            return defaults
        
        elif analysis_type == "roi_bep_planning" or analysis_type == "roi_bep_selling":
            defaults = {
                "production_cost": formatted_vars.get("production_cost", 570111934.0),
                "marketing_budget": formatted_vars.get("marketing_budget", 8098512.5),
                "ticket_price": formatted_vars.get("ticket_price", 40349.5),
                "capacity": formatted_vars.get("capacity", 280.0),
                "variable_cost_rate": formatted_vars.get("variable_cost_rate", 0.17755),
                "accumulated_sales": formatted_vars.get("accumulated_sales", 105.0),
                "duration": formatted_vars.get("duration", 1)
            }
            return defaults
        
        elif analysis_type == "ticket_risk_selling":
            defaults = {
                "genre": formatted_vars.get("genre", "ë®¤ì§€ì»¬"),
                "region": formatted_vars.get("region", "ì„œìš¸íŠ¹ë³„ì‹œ"),
                "start_date_numeric": formatted_vars.get("start_date_numeric", 1.0),
                "capacity": formatted_vars.get("capacity", 280.0),
                "star_power": formatted_vars.get("star_power", 1.0),
                "daily_sales": formatted_vars.get("daily_sales", 2.0),
                "accumulated_sales": formatted_vars.get("accumulated_sales", 105.0),
                "ad_exposure": formatted_vars.get("ad_exposure", 303284.5),
                "sns_mention_daily": formatted_vars.get("sns_mention_daily", 0.0),
                "promo_event_flag": formatted_vars.get("promo_event_flag", 0),
                "duration": formatted_vars.get("duration", 1)
            }
            return defaults
        
        return formatted_vars
        
    # í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê°€ìƒ ì‘ë‹µ ì œê³µ í•¨ìˆ˜
    def _get_fallback_response(self, analysis_type):
        """API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê°€ìƒ ì‘ë‹µ ìƒì„±"""
        logger.info(f"{analysis_type}ì— ëŒ€í•œ ê°€ìƒ ì‘ë‹µ ìƒì„±")
        
        if analysis_type == "accumulated_sales_planning":
            return {"predictions": [15000]}
        elif analysis_type == "roi_bep_planning":
            return {"predictions": [15.5, 8000]}
        elif analysis_type == "accumulated_sales_selling":
            return {"predictions": [20000]}
        elif analysis_type == "roi_bep_selling":
            return {"predictions": [18.5, 9500]}
        elif analysis_type == "ticket_risk_selling":
            return {"risk_labels": [0]}
        elif analysis_type == "genre_stats":
            return {
                "genre_stats": {
                    "genre": ["ë®¤ì§€ì»¬", "ì—°ê·¹", "ì„œì–‘ìŒì•…(í´ë˜ì‹)", "ëŒ€ì¤‘ìŒì•…", "ë¬´ìš©(ì„œì–‘/í•œêµ­)", "í•œêµ­ìŒì•…(êµ­ì•…)", "ì„œì»¤ìŠ¤/ë§ˆìˆ ", "ë³µí•©"],
                    "performance_count": [3006, 2932, 8199, 3970, 840, 1356, 835, 440],
                    "audience": [7831448, 2836558, 3290415, 6302709, 606737, 436947, 692155, 225613],
                    "ticket_revenue": [465122497, 73411508, 100996136, 756977444, 20633422, 4869454, 28565775, 2799943]
                }
            }
        elif analysis_type == "regional_stats":
            return {
                "regional_stats": {
                    "region": ["ì„œìš¸", "ê²½ê¸°", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ"],
                    "performance_count": [9966, 2917, 1311, 1279, 687],
                    "show_count": [82160, 10807, 5429, 5146, 2231],
                    "total_ticket_sales": [13384094, 2549324, 1062750, 1002533, 823153],
                    "total_ticket_revenue": [946566611, 127171128, 82282070, 56503689, 76098489]
                }
            }
        elif analysis_type == "venue_scale_stats":
            return {
                "venue_scale_stats": {
                    "year": [2024, 2024, 2024, 2024, 2024, 2024, 2024],
                    "scale": ["10,000ì„ ì´ìƒ", "5,000~10,000ì„ ë¯¸ë§Œ", "1,000~5,000ì„ ë¯¸ë§Œ", "500~1,000ì„ ë¯¸ë§Œ", "300~500ì„ ë¯¸ë§Œ", "1~300ì„ ë¯¸ë§Œ", "0ì„(ì¢Œì„ë¯¸ìƒ)"],
                    "performance_count": [132, 131, 4038, 4558, 4135, 7147, 1493],
                    "total_ticket_sales": [2682816, 734900, 8227156, 3504875, 2762187, 3429763, 898841]
                }
            }
        
        return {"error": "ì•Œ ìˆ˜ ì—†ëŠ” ë¶„ì„ ìœ í˜•"}

    
    # ML ì§ì ‘ í˜¸ì¶œ (api/chatbot/response ë¡œ ê²°ê³¼ ë°ì´í„° ë°˜í™˜)
    async def _call_ml_api(self, analysis_type, formatted_vars):
        """ML API ë‚´ë¶€ ì§ì ‘ í˜¸ì¶œ"""
        try:
            # ML ëª¨ë“ˆì—ì„œ í•¨ìˆ˜ ì§ì ‘ ì„í¬íŠ¸
            from ModelPredictionModule.analysis_module import (
                predict_acc_sales_planning,
                predict_acc_sales_selling,
                predict_roi_bep_planning,
                predict_roi_bep_selling,
                predict_ticket_risk,
                get_genre_stats,
                get_regional_stats,
                get_venue_scale_stats
            )
            
            # í†µê³„ ë¶„ì„ (ì…ë ¥ ë°ì´í„° ì—†ì´ í˜¸ì¶œ)
            if analysis_type == "genre_stats":
                stats = get_genre_stats()
                return stats
            
            elif analysis_type == "regional_stats":
                stats = get_regional_stats()
                return stats
                
            elif analysis_type == "venue_scale_stats":
                stats = get_venue_scale_stats()
                return stats
            
            # ê¸°ì¡´ ì˜ˆì¸¡ ë¶„ì„ (ì…ë ¥ ë°ì´í„° í•„ìš”)
            # ë‹¨ì¼ ê°ì²´ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ í¬ì¥
            input_data = [formatted_vars]
            
            # ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ
            if analysis_type == "accumulated_sales_planning":
                preds = predict_acc_sales_planning(input_data)
                return {"predictions": preds}
            elif analysis_type == "roi_bep_planning":
                preds = predict_roi_bep_planning(input_data)
                return {"predictions": preds}
            elif analysis_type == "accumulated_sales_selling":
                preds = predict_acc_sales_selling(input_data)
                return {"predictions": preds}
            elif analysis_type == "roi_bep_selling":
                preds = predict_roi_bep_selling(input_data)
                return {"predictions": preds}
            elif analysis_type == "ticket_risk_selling":
                preds = predict_ticket_risk(input_data)
                return {"risk_labels": preds}
            else:
                return self._get_fallback_response(analysis_type)
        except Exception as e:
            logger.error(f"ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
            return self._get_fallback_response(analysis_type)
    
    # ë¶„ì„ ê²°ê³¼ í•´ì„ í•¨ìˆ˜
    def _interpret_analysis_results(self, analysis_type, results):
        """ë¶„ì„ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ì¸ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            logger.debug(f"ë¶„ì„ ìœ í˜•: {analysis_type}, ê²°ê³¼ êµ¬ì¡°: {type(results)}")
            logger.debug(f"ê²°ê³¼ ë‚´ìš©: {results}")
            
            if "error" in results:
                return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {results['error']}"
            
            # í‹°ì¼“ ë¦¬ìŠ¤í¬ ë¶„ì„ (analysis_type ë˜ëŠ” risk_labelsë¡œ íŒë‹¨)
            if analysis_type == "ticket_risk_selling" or "risk_labels" in results:
                if "risk_labels" in results:
                    risk_labels = results["risk_labels"]
                    # ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    if not isinstance(risk_labels, list):
                        risk_labels = [risk_labels]
                    # ë¹ˆ ë¦¬ìŠ¤íŠ¸ë©´ ê¸°ë³¸ê°’ ì„¤ì •
                    if not risk_labels:
                        risk_labels = [0]
                        
                    try:
                        risk_label = int(float(risk_labels[0]))
                    except (ValueError, TypeError, IndexError):
                        risk_label = 0
                    
                    # 0, 1, 2 ê°’ì— ë”°ë¥¸ ë¦¬ìŠ¤í¬ ë ˆë²¨ ì„¤ì •
                    risk_levels = {
                        0: "ë‚®ìŒ",
                        1: "ì¤‘ê°„",
                        2: "ë†’ìŒ"
                    }
                    risk_level = risk_levels.get(risk_label, "ì•Œ ìˆ˜ ì—†ìŒ")
                    
                    risk_text = f"âš ï¸ í‹°ì¼“ íŒë§¤ ìœ„í—˜ë„: {risk_level}\n"
                    
                    # ë¦¬ìŠ¤í¬ ë ˆë²¨ë³„ ì¡°ì–¸
                    if risk_label == 0:
                        advice = "í˜„ì¬ íŒë§¤ ì¶”ì„¸ê°€ ì–‘í˜¸í•©ë‹ˆë‹¤. í˜„ì¬ ì „ëµì„ ìœ ì§€í•˜ì„¸ìš”."
                    elif risk_label == 1:
                        advice = "íŒë§¤ ì¶”ì„¸ê°€ ê¸°ëŒ€ì— ë¯¸ì¹˜ì§€ ëª»í•©ë‹ˆë‹¤. ë§ˆì¼€íŒ… í™œë™ ê°•í™”ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”."
                    elif risk_label == 2:
                        advice = "íŒë§¤ ìœ„í—˜ë„ê°€ ë†’ìŠµë‹ˆë‹¤. ì¶”ê°€ ë§ˆì¼€íŒ… í™œë™ê³¼ í”„ë¡œëª¨ì…˜ì„ ì ê·¹ ê³ ë ¤í•˜ì„¸ìš”."
                    else:
                        advice = "íŒë§¤ ì¶”ì„¸ë¥¼ ë¶„ì„í•  ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                    
                    return risk_text + advice
            
            # í†µê³„ ë¶„ì„ ê²°ê³¼ í•´ì„
            if analysis_type == "genre_stats":
                if "genre_stats" in results:
                    stats = results["genre_stats"]
                    genres = stats.get("genre", [])
                    counts = stats.get("performance_count", [])
                    audiences = stats.get("audience", [])
                    revenues = stats.get("ticket_revenue", [])
                    
                    # ìƒìœ„ 3ê°œ ì¥ë¥´ ì¶”ì¶œ
                    if len(genres) > 0:
                        # ê³µì—° ì‘ìˆ˜ ê¸°ì¤€ ìƒìœ„ 3ê°œ
                        top_genres_idx = sorted(range(len(counts)), key=lambda i: counts[i], reverse=True)[:3]
                        top_genres = [genres[i] for i in top_genres_idx]
                        top_counts = [counts[i] for i in top_genres_idx]
                        
                        response = f"ğŸ­ ì¥ë¥´ë³„ í†µê³„ ë¶„ì„ ê²°ê³¼:\n\n"
                        response += f"ê³µì—° ì‘í’ˆ ìˆ˜ê°€ ê°€ì¥ ë§ì€ ì¥ë¥´ëŠ” '{top_genres[0]}'ë¡œ {top_counts[0]}ê°œ ì‘í’ˆì´ ê³µì—°ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
                        response += f"ê·¸ ë‹¤ìŒìœ¼ë¡œ '{top_genres[1]}'({top_counts[1]}ê°œ), '{top_genres[2]}'({top_counts[2]}ê°œ) ìˆœì…ë‹ˆë‹¤.\n\n"
                        
                        # ì´ ê³µì—° ì‘í’ˆ ìˆ˜ì™€ ê´€ê° ìˆ˜
                        total_performances = sum(counts)
                        total_audience = sum(audiences)
                        total_revenue = sum(revenues)
                        
                        response += f"ì „ì²´ {len(genres)}ê°œ ì¥ë¥´ì—ì„œ ì´ {total_performances}ê°œ ì‘í’ˆì´ ê³µì—°ë˜ì—ˆìœ¼ë©°, "
                        response += f"ì´ ê´€ê° ìˆ˜ëŠ” {total_audience:,}ëª…, í‹°ì¼“ ë§¤ì¶œì•¡ì€ {total_revenue:,}ì›ì…ë‹ˆë‹¤.\n"
                        
                        return response
                        
                return "ì¥ë¥´ë³„ í†µê³„ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤."
                
            elif analysis_type == "regional_stats":
                if "regional_stats" in results:
                    stats = results["regional_stats"]
                    regions = stats.get("region", [])
                    counts = stats.get("performance_count", [])
                    shows = stats.get("show_count", [])
                    sales = stats.get("total_ticket_sales", [])
                    
                    if len(regions) > 0:
                        response = f"ğŸ“ ì§€ì—­ë³„ í†µê³„ ë¶„ì„ ê²°ê³¼:\n\n"
                        response += f"ê³µì—°ì´ ê°€ì¥ ë§ì´ ì—´ë¦° ì§€ì—­ì€ '{regions[0]}'ë¡œ {counts[0]}ê°œ ê³µì—°, {shows[0]}íšŒ ìƒì—°ì´ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
                        
                        # ìƒìœ„ 3ê°œ ì§€ì—­ ë¹„êµ
                        if len(regions) >= 3:
                            response += f"ê·¸ ë‹¤ìŒìœ¼ë¡œ '{regions[1]}'({counts[1]}ê°œ), '{regions[2]}'({counts[2]}ê°œ) ìˆœì…ë‹ˆë‹¤.\n\n"
                        
                        # í‹°ì¼“ íŒë§¤ ë¹„êµ
                        if len(sales) > 0:
                            top_sales_idx = sorted(range(len(sales)), key=lambda i: sales[i], reverse=True)[0]
                            response += f"í‹°ì¼“ íŒë§¤ê°€ ê°€ì¥ ë§ì€ ì§€ì—­ì€ '{regions[top_sales_idx]}'ë¡œ ì´ {sales[top_sales_idx]:,}ì¥ì´ íŒë§¤ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
                        
                        return response
                        
                return "ì§€ì—­ë³„ í†µê³„ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤."
                
            elif analysis_type == "venue_scale_stats":
                if "venue_scale_stats" in results:
                    stats = results["venue_scale_stats"]
                    years = stats.get("year", [])
                    scales = stats.get("scale", [])
                    counts = stats.get("performance_count", [])
                    sales = stats.get("total_ticket_sales", [])
                    
                    if len(years) > 0 and len(scales) > 0:
                        # ìµœì‹  ì—°ë„ ë°ì´í„° ì¶”ì¶œ
                        latest_year = max(years) if years else 0
                        latest_year_indices = [i for i, y in enumerate(years) if y == latest_year]
                        
                        latest_scales = [scales[i] for i in latest_year_indices]
                        latest_counts = [counts[i] for i in latest_year_indices]
                        
                        # ê°€ì¥ ë§ì€ ê³µì—°ì´ ì—´ë¦°
                        if latest_counts:
                            max_idx = latest_counts.index(max(latest_counts))
                            response = f"ğŸ›ï¸ ê³µì—°ì¥ ê·œëª¨ë³„ í†µê³„ ë¶„ì„ ê²°ê³¼ ({latest_year}ë…„):\n\n"
                            response += f"ê°€ì¥ ë§ì€ ê³µì—°ì´ ì—´ë¦° ê³µì—°ì¥ ê·œëª¨ëŠ” '{latest_scales[max_idx]}'ë¡œ {latest_counts[max_idx]}ê°œ ê³µì—°ì´ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
                            
                            # ì‘ë…„ê³¼ ë¹„êµ
                            prev_year = latest_year - 1
                            prev_year_indices = [i for i, y in enumerate(years) if y == prev_year]
                            
                            if prev_year_indices:
                                prev_scales = [scales[i] for i in prev_year_indices]
                                prev_counts = [counts[i] for i in prev_year_indices]
                                
                                # ê°™ì€ ê·œëª¨ ì°¾ê¸°
                                if latest_scales[max_idx] in prev_scales:
                                    prev_idx = prev_scales.index(latest_scales[max_idx])
                                    change = latest_counts[max_idx] - prev_counts[prev_idx]
                                    change_text = f"ì¦ê°€í–ˆìŠµë‹ˆë‹¤" if change > 0 else f"ê°ì†Œí–ˆìŠµë‹ˆë‹¤" if change < 0 else "ë™ì¼í•©ë‹ˆë‹¤"
                                    response += f"ì´ëŠ” {prev_year}ë…„({prev_counts[prev_idx]}ê°œ)ì— ë¹„í•´ {abs(change)}ê°œ {change_text}.\n"
                            
                            return response
                        
                return "ê³µì—°ì¥ ê·œëª¨ë³„ í†µê³„ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤."
            
            # ì¤‘ì²©ëœ predictions êµ¬ì¡° ì²˜ë¦¬
            if "predictions" in results and isinstance(results["predictions"], dict):
                nested_results = results["predictions"]
                
                if analysis_type == "accumulated_sales_planning" or analysis_type == "accumulated_sales_selling":
                    # ì¤‘ì²©ëœ predictions ë°°ì—´ì—ì„œ ì²« ë²ˆì§¸ ê°’ ì¶”ì¶œ
                    predictions_array = nested_results.get("predictions", [0])
                    value = predictions_array[0] if len(predictions_array) > 0 else 0
                    return f"ğŸ­ ì˜ˆìƒ ê´€ê° ìˆ˜: ì•½ {int(value):,}ëª…\n"
                    
                elif analysis_type == "roi_bep_planning" or analysis_type == "roi_bep_selling":
                    # ì¤‘ì²©ëœ predictions ë°°ì—´ì˜ ë°°ì—´ì—ì„œ ê°’ ì¶”ì¶œ
                    predictions_array = nested_results.get("predictions", [[0, 0]])
                    value = predictions_array[0] if len(predictions_array) > 0 else [0, 0]
                    
                    roi = value[0] if len(value) > 0 else 0
                    bep = value[1] if len(value) > 1 else 0
                    
                    roi_percentage = roi * 100  # ë¹„ìœ¨ì„ í¼ì„¼íŠ¸ë¡œ ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
                    
                    roi_text = f"ğŸ“ˆ ì˜ˆìƒ ROI(íˆ¬ììˆ˜ìµë¥ ): {roi_percentage:.2f}%\n"
                    bep_text = f"âš–ï¸ ì†ìµë¶„ê¸°ì (BEP): ì•½ {int(bep):,}ëª…ì˜ ê´€ê°\n"
                    
                    return roi_text + bep_text
            
            # ê¸°ì¡´ ë¹„ì¤‘ì²© êµ¬ì¡° ì²˜ë¦¬ (ì´ì „ êµ¬ì¡°ì™€ì˜ í˜¸í™˜ì„± ìœ ì§€)
            elif "predictions" in results and isinstance(results["predictions"], list):
                if analysis_type == "accumulated_sales_planning" or analysis_type == "accumulated_sales_selling":
                    value = results.get("predictions", [0])[0]
                    return f"ğŸ­ ì˜ˆìƒ ê´€ê° ìˆ˜: ì•½ {int(value):,}ëª…\n"
                    
                elif analysis_type == "roi_bep_planning" or analysis_type == "roi_bep_selling":
                    value = results.get("predictions", [0, 0])
                    roi = value[0]
                    bep = value[1] if len(value) > 1 else 0
                    
                    roi_text = f"ğŸ“ˆ ì˜ˆìƒ ROI(íˆ¬ììˆ˜ìµë¥ ): {roi:.2f}%\n"
                    bep_text = f"âš–ï¸ ì†ìµë¶„ê¸°ì (BEP): ì•½ {int(bep):,}ëª…ì˜ ê´€ê°\n"
                    
                    return roi_text + bep_text
                    
            return "ë¶„ì„ ê²°ê³¼ë¥¼ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        except Exception as e:
            logger.error(f"ê²°ê³¼ í•´ì„ ì˜¤ë¥˜: {str(e)}", exc_info=True)
            return f"ê²°ê³¼ í•´ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            
    
    # ê¸°ì¡´ handle_user_input í•¨ìˆ˜ í™•ì¥
    async def handle_user_input(self, user_input, history):
        if not isinstance(history, list):
            history = []

        # 1. ì‚¬ìš©ì ì˜ë„ ë¶„ë¥˜: ìˆ˜ì§‘ / ê²€ìƒ‰ / ë¶„ì„
        intent = self.classifier.classify_intent(user_input)
        stage = self.detector.detect_stage(user_input)
        
        logger.debug(f"ì‚¬ìš©ì ì…ë ¥: '{user_input}'")
        logger.debug(f"ê°ì§€ëœ ì˜ë„: {intent}")
        logger.debug(f"ê°ì§€ëœ ë‹¨ê³„: {stage}")
        
        reply_parts = []
        analysis_results = {}

        # 2-1. JSON ë³€ìˆ˜ ìˆ˜ì§‘
        if intent in ["ìˆ˜ì§‘"]:
            extracted = self.extractor.extract_variables(user_input, fallback_key=self.last_asked_key)
            logger.debug(f"ì¶”ì¶œëœ ë³€ìˆ˜: {extracted}")
            
            for key, val in extracted.items():
                if val is not None:
                    self.collected_vars[key] = val

        # 2-2. ë¶„ì„ ìš”ì²­ ì²˜ë¦¬ - ì˜ë„ê°€ "ë¶„ì„" ë˜ëŠ” "í˜¼í•©"ì¼ ë•Œë§Œ ìˆ˜í–‰
        if intent in ["ë¶„ì„"]:
            analysis_types = self._determine_analysis_type(user_input, stage)
            logger.debug(f"ê²°ì •ëœ ë¶„ì„ ìœ í˜•: {analysis_types}")
            
            # ë¶„ì„ ê²°ê³¼ ëª¨ìŒ
            analysis_results_text = []
            
            for analysis_type in analysis_types:
                formatted_vars = self._format_variables_for_ml_api(analysis_type)
                logger.debug(f"API í˜¸ì¶œ ì „ ë³€ìˆ˜: {formatted_vars}")
                
                api_result = await self._call_ml_api(analysis_type, formatted_vars)
                logger.debug(f"API ì‘ë‹µ: {api_result}")
                
                result_text = self._interpret_analysis_results(analysis_type, api_result)
                logger.debug(f"í•´ì„ëœ ê²°ê³¼: {result_text}")
                
                analysis_results_text.append(result_text)
                analysis_results[analysis_type] = api_result
            
            # ë¶„ì„ ê²°ê³¼ ì¶”ê°€
            if analysis_results_text:
                analysis_text = "## ğŸ“Š ë¶„ì„ ê²°ê³¼\n\n" + "\n".join(analysis_results_text)
                logger.debug(f"ì¶”ê°€ë  ë¶„ì„ ê²°ê³¼: {analysis_text}")
                reply_parts.append(analysis_text)
            else:
                logger.warning("ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")

        # 2-3. ì¶”ê°€ ìœ ë„ ì§ˆë¬¸ ìƒì„±
        if intent in ["ìˆ˜ì§‘", "ê²€ìƒ‰"]:
            next_question, next_key = self.prompter.generate(self.collected_vars, user_input, stage)

            if next_question and next_question not in reply_parts:
                reply_parts.append(next_question)

            if next_key:
                self.last_asked_key = next_key

        # ë¶„ì„ì¼ ê²½ìš°, ì¶”ê°€ ë©˜íŠ¸ í•œ ì¤„
        elif intent == "ë¶„ì„":
            analysis_followup_comment = "ì¶”ê°€ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì‹¶ì€ í•­ëª©ì´ ìˆë‹¤ë©´ ë” ë§ì”€í•´ ì£¼ì„¸ìš”!"
            if analysis_followup_comment not in reply_parts:
                reply_parts.append(analysis_followup_comment)

        # 3. AI ë¬¸ì„œ ê²€ìƒ‰
        if intent in ["ê²€ìƒ‰"]:
            summary = self.search.query(user_input)
            self.summary = summary
            reply_parts.append("ğŸ“– ê´€ë ¨ ë¬¸ì„œ ìš”ì•½:\n\n" + summary)

        # 4. ì‘ë‹µ ë° ìƒíƒœ ë°˜í™˜
        full_reply = "\n\n".join(reply_parts)
        history.append((user_input, full_reply))
        
        logger.debug(f"ìµœì¢… ì‘ë‹µ êµ¬ì„± ìš”ì†Œ: {reply_parts}")
        logger.debug(f"í˜„ì¬ ìˆ˜ì§‘ëœ ë³€ìˆ˜: {self.collected_vars}")

        return {
            "chat_history": history,
            "response_text": full_reply,
            "structured_data": self.collected_vars,
            "related_docu" : self.summary,
            "analysis_results": analysis_results,
            "intent": intent,
            "stage": stage,
        }